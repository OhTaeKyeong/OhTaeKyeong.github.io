---
layout: post
title: "[오태경의 머신러닝] 5일 단기 4일차 (1)"
excerpt: "목적함수 - 무엇을 최적화 하지?"
categories:
- Excel
tags:
- Excel
- 오태경의 머신러닝
- 5일 단기
last_modified_at: 2021-07-29T13:19:00+09:00
comments : true
---
<hr>

<h2>- 목차</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드3.PNG">
</div>
<br>

<h2>- Intro</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드4.PNG">
</div>

<br>
<h2>- 목적함수란</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드5.PNG">
</div>

> 실제 함수와의 오차를 나타내는 목적함수는 "손실함수"라고도 하며, 경사하강법을 통해 최소화 해야 할 대상이 된다.

<br>
<h2>- 손실함수로써의 MSE와 MAE</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드6.PNG">
</div>

> 경우에 따라 다르지만, 목적함수로 MSE를 사용하는 것이 일반적이다.

<br>
<h2>- 가중치의 "전역 해"로의 수렴 가능성</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드7.PNG">
</div>

> 여기서 말하는 "수렴성"은 가중치가 손실함수가 최소가 되는 지점인 곳, 즉 경사하강법을 진행함에 따라 "전역 해"로 도달할 수 있는 가능성을 의미한다. 전역해로의 수렴 가능성은 손실함수의 Convexity와 연관이 있다.

<br>
<h2>- 예제 1</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드8.PNG">
</div>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드9.PNG">
</div>

> 물론 데이터의 개수가 많다면 그 각각의 데이터에 대해 그래프를 하나하나 그려볼 수 있다. 여기서는 목적함수에서 가중치의 전역해 수렴 가능성을 판단하기 위해 Convexity를 확인해 보는 의미로 하나의 데이터만 사용하였다. 가끔 신경망 모델을 학습하면서 학습이 잘 이루어지지 않는 데이터들이 존재하는데, 그러한 데이터를 대상으로 손실함수의 Convexity를 확인해보는 것도 좋을 것 같다.

<br>
<h2>- 예제 2</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드10.PNG">
</div>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드11.PNG">
</div>

> 참고로 여기서는 단층 퍼셉트론 모델을 대상으로 그래프를 그렸기 때문에 Local minimum이 존재하지 않아 언젠가는 Global minimum에 도달하겠지만, 신경망이 깊어질수록 w와 E의 관계가 복잡해지기 때문에 수렴 가능성은 더욱 낮아지게 된다.

<br>