---
layout: post
title: "[오태경의 머신러닝] 5일 단기 4일차 (3)"
excerpt: "가중치 초기화 - 적절한 초기화 방법은?"
categories:
- Excel
tags:
- Excel
- 오태경의 머신러닝
- 5일 단기
last_modified_at: 2021-07-30T12:06:00+09:00
comments : true
---
<hr>

<h2>- Intro</h2>
<div style="text-align: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드24.PNG">
</div>

<br>
<h2>- 가중치 초기화의 중요성</h2>
<div style="text-align: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드25.PNG">
</div>
<div style="text-align: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드26.PNG">
</div>

> 추가적으로 가중치를 모두 0으로 설정했을 때, 출력 노드의 활성화함수가 시그모이드라면 출력 노드의 가중치에 대해서만 학습이 이루어진다.

<br>
<h2>- 효과적인 가중치 초기화?</h2>
<div style="text-align: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드27.PNG">
</div>

> 엑셀을 활용하여 이진 분류 신경망을 구성한 경우에 한해, 학습 전 초기화된 신경망의 출력이 0.5 부근의 값을 가질 때 학습 속도가 빠르며 그래디언트 폭주 가능성도 낮아진다는 사실을 경험적으로 터득하였다. 위의 경험식을 쓴다면 층의 개수에 관계 없이 출력 노드 값을 0.3~0.7 범위 안에서 안정적으로 뽑아낼 수 있다.

> 코딩 환경이 파이썬이라면 활성화함수에 따라 글로럿 초기화, He 초기화 등을 라이브러리로 제공하고 있지만 일반적인 환경에서는 ReLU + He 초기화가 국룰인 것 같다.

<br>
<h2>- 예제 5</h2>
<div style="text-align: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드28.PNG">
</div>
<div style="text-align: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드29.PNG">
</div>

{% highlight vb %}
Const L_rate = 0.8

Public Function sigmoid(sigmoid_input)
    sigmoid = 1 / (1 + Exp(-sigmoid_input))
End Function

'경사하강법 단추 코드
Sub 경사하강법()
For k = 1 To 300
'가중치가 (-10, -10)인 경우
w = Cells(1, 5).Value
b = Cells(1, 6).Value
x = Cells(1, 1).Value

y = sigmoid(w * x + b)
Cells(1, 3) = y
ans = Cells(1, 2).Value
w = w - L_rate * (y - ans) * y * (1 - y) * x
b = b - L_rate * (y - ans) * y * (1 - y)

Cells(1, 5) = w
Cells(1, 6) = b

'가중치가 (-1, 1)인 경우
w = Cells(2, 5).Value
b = Cells(2, 6).Value
x = Cells(2, 1).Value

y = sigmoid(w * x + b)
Cells(2, 3) = y
ans = Cells(1, 2).Value
w = w - L_rate * (y - ans) * y * (1 - y) * x
b = b - L_rate * (y - ans) * y * (1 - y)

Cells(2, 5) = w
Cells(2, 6) = b
Next k
End Sub
{% endhighlight %}

> 같은 알고리즘을 사용한다고 하더라도 초기 가중치에 따라 학습 가능성이 달라질 수 있다는 것을 보여주는 예제이다.

<br>