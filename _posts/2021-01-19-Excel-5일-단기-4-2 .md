---
layout: post
title: "[오태경의 머신러닝] 5일 단기 4일차 (2)"
excerpt: "크로스 엔트로피 - 새로운 목적함수"
categories:
- Excel
tags:
- Excel
- 오태경의 머신러닝
- 5일 단기
last_modified_at: 2021-07-29T16:16:00+09:00
comments : true
---
<hr>

<h2>- Intro</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드12.PNG">
</div>

<br>
<h2>- 엔트로피 개념</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드13.PNG">
</div>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드14.PNG">
</div>

> 위의 경우에는 분류하고자 하는 클래스가 2개이므로, 사실 정확이는 ln 대신에 log2를 써서 계산을 해야 한다. 하지만 손실함수로써 크로스 엔트로피를 유도할 때에 ln을 사용하는 것이 편리할 뿐만 아니라 수학적인 의미에서 큰 차이가 없기 때문에 엔트로피에 적용되는 로그함수를 자연로그로 통일하겠다.

<br>
<h2>- 크로스 엔트로피 손실함수</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드15.PNG">
</div>

> 위에서 도출된 함수는 이진분류에 대한 CEE이다.

<br>
<h2>- 예제 3</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드16.PNG">
</div>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드17.PNG">
</div>

> 로지스틱 회귀 모델에서 CEE는 Convex하다.

<br>
<h2>- CEE의 미분</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드18.PNG">
</div>

> 우연인지 필연인지, 시그모이드 + CEE의 가중치 업데이트 식은 교육 1일차에 등장한 회귀 모델의 가중치 업데이트 식과 형태가 완전히 동일하다.

<br>
<h2>- 공지</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드19.PNG">
</div>

> 3일차에도 잠시 언급을 했지만, 그 당시 착오로 코딩했던 목적함수가 CEE였다. 사실 어느 것을 사용하든지 결과는 잘 나오겠지만, 아직 배우지 않은 목적함수를 사용한 점에 대한 사과의 공지였다.

<br>
<h2>- 예제 4</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드20.PNG">
</div>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드21.PNG">
</div>

{% highlight vb %}
Const L_rate = 0.08
Dim x(1 To 2) As Double
Dim w(1 To 2) As Double
Dim b As Double

Public Function sigmoid(sigmoid_input)
    sigmoid = 1 / (1 + Exp(-sigmoid_input))
End Function

'경사하강법 단추 코드
Sub 경사하강법()

For k = 1 To 1000

'MSE
w(1) = Cells(1, 7).Value
w(2) = Cells(1, 8).Value
b = Cells(1, 9).Value

For i = 1 To 6

    x(1) = Cells(i, 1).Value
    x(2) = Cells(i, 2).Value

    y = sigmoid(w(1) * x(1) + w(2) * x(2) + b)

    Cells(i, 4) = y

    ans = Cells(i, 3).Value

    w(1) = w(1) - L_rate * (y - ans) * y * (1 - y) * x(1)
    w(2) = w(2) - L_rate * (y - ans) * y * (1 - y) * x(2)
    b = b - L_rate * (y - ans) * y * (1 - y)

Next i

Cells(1, 7) = w(1)
Cells(1, 8) = w(2)
Cells(1, 9) = b

'CEE
w(1) = Cells(2, 7).Value
w(2) = Cells(2, 8).Value
b = Cells(2, 9).Value

For i = 1 To 6

    x(1) = Cells(i, 1).Value
    x(2) = Cells(i, 2).Value

    y = sigmoid(w(1) * x(1) + w(2) * x(2) + b)

    Cells(i, 5) = y

    ans = Cells(i, 3).Value

    w(1) = w(1) - L_rate * (y - ans) * x(1)
    w(2) = w(2) - L_rate * (y - ans) * x(2)
    b = b - L_rate * (y - ans)

Next i

Cells(2, 7) = w(1)
Cells(2, 8) = w(2)
Cells(2, 9) = b

Next k

End Sub

{% endhighlight %}

<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드22.PNG">
</div>

{% highlight vb %}
'MSE로 최적화 된 결정경계
Public Function MSE(MSE_input)
w(1) = Cells(1, 7).Value
w(2) = Cells(1, 8).Value
b = Cells(1, 9).Value
MSE = (w(1) * MSE_input + b) / (-w(2))
End Function

'CEE로 최적화 된 결정경계
Public Function CEE(CEE_input)
w(1) = Cells(2, 7).Value
w(2) = Cells(2, 8).Value
b = Cells(2, 9).Value
CEE = (w(1) * CEE_input + b) / (-w(2))
End Function
{% endhighlight %}

> MSE와 CEE는 최적화 해야할 목적을 다르게 표현할 뿐 학습만 완료된다면 신경망이 어떤 형태로 수렴될 지에는 영향을 크게 주지 않는다. 각자 다른 목적함수가 적용되었더라도 위 그림에서 볼 수 있듯이 큰 차이가 없다.

<br>
<h2>- 최적화 과정에서 수렴성 문제</h2>
<div style="align-items: center;">
    <img src="/assets/post-image/Excel-5일-단기-4/슬라이드23.PNG">
</div>

> 가중치의 Global minimum으로의 수렴 가능성이 가지는 한계는 목적함수가 해결해 주지 않는다.

<br>